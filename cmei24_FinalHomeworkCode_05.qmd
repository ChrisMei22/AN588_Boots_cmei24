---
title: "cmei24_OriginalHomeworkCode_05"
format: html
editor: visual
---

## AN/BI588 Homework 5 - Boots for Days

\[1\] Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your \\beta coeffiecients (slope and intercept).

\[2\] Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each \\beta coefficient.

```{r}
library(tidyverse)
library(curl)
```

## 1 - Log(HomeRange_km2) vs. Log(Body_mass_female_mean)

```{r}
KC_data <- read_csv(curl(url = "https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/refs/heads/master/AN588_Spring25/KamilarAndCooperData.csv"))
head(KC_data)
```

Create the variables that we need using the `mutate()` function and use `colnames()` to make sure that everything looks good!

```{r}
KC_data <- KC_data %>% mutate(Log_HomeRange_km2 = log(HomeRange_km2),
                              Log_Body_mass_female_mean = log(Body_mass_female_mean))

colnames(KC_data)
```

Insert the data and the columns needed into the model and see the coefficients

```{r}
range_body_model <- lm(data = KC_data, Log_HomeRange_km2 ~ Log_Body_mass_female_mean)
coef(range_body_model)
```

```{r}
coef(range_body_model)[[2]] # This only shows the beta slope coefficient
```

Let's plot this!

```{r}
ggplot(data = KC_data, aes(x = Log_Body_mass_female_mean, y = Log_HomeRange_km2)) +
  geom_point() +
  geom_smooth(method = "lm", formula = y ~ x)
```

## 2 - Bootstrapping

We need to see how many total entries we have in the dataset:

```{r}
length(KC_data$Log_Body_mass_female_mean)
```

Let's assume that we will bootstrap 1000 times using samples of 20 entries with replacement. This number of samples was completely arbitrary but it should be a good starting point to illustrate the bootstrapping.

```{r}
set.seed(1)
beta_collection = NULL
for (i in 1:1000){
  sample_rows <- KC_data[sample(nrow(KC_data), 20, replace = TRUE),]# We will bootstrap samples of 20 from the entire sample with replacement
  sample_model <- lm(data = sample_rows, Log_HomeRange_km2 ~ Log_Body_mass_female_mean)
  beta_collection <- c(beta_collection, coef(sample_model)[[2]]) # Store only the slope term
}

beta_collection
```

We can find the average of these bootstrapped beta coefficients:

```{r}
mean(beta_collection)
```

Estimate the standard error for each of your \\beta coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your \\beta coefficients based on the appropriate quantiles from your sampling distribution.

```{r}
SE_beta <- sd(beta_collection)
SE_beta
```

To get the 95% Confidence interval,

```{r}
ci_beta <- quantile(beta_collection, c(0.025, 0.975))
ci_beta
```

### How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in `lm()`?

To see the SE for the original model:

```{r}
og_se_beta <- summary(range_body_model)$coefficients[, "Std. Error"]
og_se_beta
```

When it comes to SE, the SE from the bootstrapped method is higher than the original one (entire dataset).

### How does the latter compare to the 95% CI estimated from your entire dataset?

To get CI from the original model:

```{r}
og_ci_beta <- confint(range_body_model)
og_ci_beta
```

Compared to the bootstrapped CI, both values are very similar with the 97.5 quantile being higher in the bootstrapped dataset and the 2.5 quantile being higher in the original dataset.

## EXTRA CREDIT

Write a FUNCTION that takes as its arguments a dataframe, “d”, a linear model, “m” (as a character string, e.g., “logHR\~logBM”), a user-defined confidence interval level, “conf.level” (with default = 0.95), and a number of bootstrap replicates, “n” (with default = 1000). Your function should return a dataframe that includes: beta coefficient names; beta coefficients, standard errors, and upper and lower CI limits for the linear model based on your entire dataset; and mean beta coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.

```{r}
lm_bootstrap <- function(d, linear_model, m, conf.level = 0.95, n = 1000){
  # First let's set up everything we need from the normal non_bootstrapped model
  lm_beta <- coef(linear_model)[[2]]
  lm_SE <- summary(linear_model)$coefficients[, "Std. Error"][[2]]
  lm_CI <- confint(linear_model, level = conf.level)
  
  # Now let's do the bootstrapping
  beta_bootstrapped = NULL
  set.seed(1)
  for (i in 1:n){
    sample_rows <- d[sample(nrow(d), 20, replace = TRUE),]
    sample_model <- lm(data = sample_rows, as.formula(m)) # Need to turn string from m as a formula, otherwise it won't work
    beta_collection <- c(beta_collection, coef(sample_model)[[2]])
  }

  # Get what you need from the bootstrapped info
  boot_beta <- mean(beta_collection)
  boot_SE <- sd(beta_collection)
  lower_CI <- (1 - conf.level)/2 # To get different quantiles if confidence level is not 0.95
  upper_CI <- 1 - lower_CI
  boot_CI <- quantile(beta_collection, c(lower_CI, upper_CI))
  
  # Put it all together in a table
  output_df <- data.frame(
    Values = c("beta_coef", "SE", "lower_CI", "upper_CI"),
    Original_lm = c(lm_beta, lm_SE, lm_CI[2], lm_CI[4]),
    Bootstrapped_lm = c(boot_beta, boot_SE, boot_CI[[1]], boot_CI[[2]])
  )
  return(output_df)
}
```

Let's test it!

```{r}
test_function <- lm_bootstrap(KC_data, range_body_model, m = "Log_HomeRange_km2 ~ Log_Body_mass_female_mean")
test_function
```

```{r}
test_function[1,3] # This is to get the beta coef from the bootstrapped lm
```

Everything checks out with what we calculated above!

## EXTRA EXTRA CREDIT

Graph each beta value from the linear model and its corresponding mean value, lower CI and upper CI from a bootstrap as a function of number of bootstraps from 10 to 200 by 10s. HINT: the beta value from the linear model will be the same for all bootstraps and the mean beta value may not differ that much!

```{r}
n_boot_list <- seq(10, 200, by = 10) # Establish a list of numbers that will go from 10 to 200 in intervals of 10

graph_df <- data.frame( # Create an empty data frame to add our data to
  n_boot = numeric(),
  beta_coef = numeric(),
  lower_CI = numeric(),
  upper_CI = numeric()
)

for(i in n_boot_list){ # Go through the list of the n_boot_list and use i as the bootstrap sample parameter in the custom lm_bootstrap() function
  
  boot_results <- lm_bootstrap(KC_data, range_body_model, m = "Log_HomeRange_km2 ~ Log_Body_mass_female_mean", n = i)
  
  values_for_df <- data.frame(n_boot = i, # Add the values obtained into a single row data frame. We need to rearrange the results becuase the function yields some different orders
                              beta_coef = boot_results[1,3],
                              lower_CI = boot_results[3,3],
                              upper_CI = boot_results[4,3])
  graph_df <- rbind(graph_df, values_for_df) # Add the single row data frame into the larger dataframe
}

head(graph_df)
```

Time to plot!

```{r}
ggplot(data = graph_df, aes(x = n_boot)) +
  # I wanted to plot all the required variables in one figure, so instead of adding y = in the line above, I did it for each geom_point()!
  # Plotting the Beta coefficient
  geom_point(aes(y = beta_coef, color = "β coefficient")) +
  # Plot Lower CI 
  geom_point(aes(y = lower_CI, color = "Lower CI")) +
  # Plot Upper CI with Color Inside aes()
  geom_point(aes(y = upper_CI, color = "Upper CI")) +
  
  
  # Since the beta coefficient and the CI values from the original lm will always remain the same, I decided to make it a horizontal line 
  geom_hline(aes(yintercept = coef(range_body_model)[[2]], color = "Original β coefficient"),
             linetype = "dashed") +
  
  # Line for lower CI
  geom_hline(aes(yintercept = ci_beta[[1]], color = "Original Lower CI"),
             linetype = "dashed") +
  
  # Line for upper CI
  geom_hline(aes(yintercept = ci_beta[[2]], color = "Original Upper CI"),
             linetype = "dashed") +
  
  # Set Y-Axis Limits to see everything more spaced out
  
  # Adding labels
  labs(title = "Bootstrapped LM vs Base LM", 
       x = "# of Bootstraps", 
       y = "Values",
       color = "Legend") +  
  # We can use this method to assign different colors to our values so we can plot them all together in one graph!
  scale_color_manual(values = c("β coefficient" = "red",
                                 "Lower CI" = "darkgreen",
                                 "Upper CI" = "darkblue",
                                "Original β coefficient" = "pink",
                                "Original Lower CI" = "lightgreen",
                                "Original Upper CI" = "lightblue"),
                     limits = c("Upper CI", "Original Upper CI", # We can use the limits argument to set our out legend title order!
                                "β coefficient", "Original β coefficient",
                                "Lower CI", "Original Lower CI")) +

  theme_minimal()

```

## Five Challenges Faced

1.  I didn't really struggle with the main assignment once I understood what was being asked of me but it was hard for me to understand the question. This tells me about the deficiencies that I have when it comes to the conceptual ideas asked of me. I understand it now!
2.  Struggled with argument m in the EXTRA CREDIT function since I didn't know I would need to turn it into a formula first using `as.formula()`
3.  In the EXTRA EXTRA CREDIT section I found it hard to think of an efficient way to put everything in the same table for ease of graphing it out later! Glad I figured it out though!
4.  The hardest part was to learn how to plot all the points from the EXTRA EXTRA CREDIT table onto my scatterplot. I learned that I can include the aes(y = ) in other areas other than the initial ggplot starting line.
5.  Learning how to correctly set up my Legend. However, with online help I was able to figure out how these things work!
